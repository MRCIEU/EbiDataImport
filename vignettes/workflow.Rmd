---
title: "workflow"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{workflow}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(EbiDataImport)
```


To obtain a dataset for a specific EBI ID:


```{r}
ebi_id <- "GCST005522"
x <- ObtainEbiDataset$new(
	ebi_id = ebi_id, 
	ftp_path=get_ftp_path(ebi_id)
)
x$download_dataset()
x$format_dataset()
x$organise_metadata()
x$write_metadata()
```

To upload to the API:

```{r}
x$datainfo$id <- x$metadata$id <- x$ebi_id <- runif(1, 100000, 999999) %>% round %>% as.character %>% paste0("ebitest-", .)
x$upload_delete(x$ebi_id)
x$upload_metadata()
x$upload_check()
x$upload_gwas()
x$upload_delete(x$ebi_id)
```

To get a list of datasets that need to be imported:

```{r}
newdats <- determine_new_datasets()
```


Complete workflow for one dataset:

```{r, eval=FALSE}

# Authorise
ieugwasr::get_access_token()

# Define ID
ebi_id <- newdats$ebi_id[1]
ebi_id <- "GCST004426"
x <- ObtainEbiDataset$new(
	ebi_id = ebi_id, 
	ftp_path=get_ftp_path(ebi_id)
)
x$download_dataset()
x$format_dataset()
x$organise_metadata()
x$write_metadata()
x$upload_metadata()
x$upload_check()
x$upload_gwas()
x$delete_wd()
```

Workflow for all datasets

```{r}
newdats <- determine_new_datasets()
newdats <- being_processed(newdats) %>% subset(., need)
ignore <- list()
for(i in 1:nrow(newdats))
{
	ebi_id <- newdats$ebi_id[i]
	message(ebi_id)
	x <- ObtainEbiDataset$new(
		ebi_id = ebi_id, 
		ftp_path = newdats$path[i]
	)
	x$download_dataset()
	x$format_dataset()
	x$organise_metadata()
	x$write_metadata()
	x$upload_metadata()
	x$upload_check()
	x$upload_gwas()
	x$delete_wd()
	rm(x)
}


ignore_list <- scan(system.file(package="EbiDataImport", "extdata/ebi_ignore_list.txt"), character())
newdats <- determine_new_datasets(blacklist=ignore_list)
newdats <- being_processed(newdats) %>% subset(., need)
ignore <- list()
for(i in 1:nrow(newdats))
{
	message(newdats$ebi_id[i])
	x <- ObtainEbiDataset$new(
		ebi_id = newdats$ebi_id[i], 
		ftp_path = newdats$path[i]
	)
	o <- x$pipeline()
	if(! "NULL" %in% class(o))
	{
		ignore[[newdats$ebi_id[i]]] <- o
	}
	rm(x)
}

```





## Lookup build



```{r}
x <- ObtainEbiDataset$new("GCST000755", ftp_path=get_ftp_path("GCST000755"))
x$download_dataset()
x$format_dataset()
```


## Suhre proteins

```{r}
ignore_list <- scan(system.file(package="EbiDataImport", "extdata/ebi_ignore_list.txt"), character())
newdats <- determine_new_datasets(blacklist=ignore_list, exclude = FALSE)
suhre <- subset(newdats, grepl("Suhr", path))
suhre <- separate(suhre, path, sep="/", into=c("p1","p2","p3"), remove=F)
temp <- do.call(rbind, strsplit(suhre$p3, split="_"))
suhre$igd_id <- paste0("prot-c-", temp[,1], "_", temp[,2])
suhre$igd_id

traitinfo <- data.table::fread("http://metabolomics.helmholtz-muenchen.de/pgwas/download/probeanno.tsv", sep="\t")
traitinfo$igd_id <- paste0("prot-c-", traitinfo$seqid)

suhre <- merge(suhre, traitinfo, by="igd_id")
save(suhre, file="suhre.rdata")



load("suhre.rdata")
for(i in 1:nrow(suhre))
{
	x <- ObtainEbiDataset$new(
		ebi_id=suhre$ebi_id[i],
		ftp_path=suhre$path[i],
		igd_id=suhre$igd_id[i],
		traitname=suhre$target[i]
	)
	x$download_dataset()
	x$pipeline()
}


```

